{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RunningModel Mean.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IzmPI1l-iMvC"},"source":["# **Load Data + Import Libraries**"]},{"cell_type":"code","metadata":{"id":"7zd5KMKyS8CX"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from numpy import loadtxt\n","from sklearn.model_selection import train_test_split, cross_val_score \n","from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score,confusion_matrix\n","import pickle\n","from tqdm import tqdm\n","import os\n","random_state = 42"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"rnV537_-TDcE"},"source":["#change path to your dataset path in this cell\n","fidf = np.load(\".././3Dresnext101_2s_data_feature/fight.npy\")\n","nofidf = np.load(\".././3Dresnext101_2s_data_feature/nofight.npy\") "],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dN4102UhVO6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"54db1efa-b259-434e-93a7-26834a3e40fa"},"source":["fidf.shape, nofidf.shape"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((150, 4, 2048), (150, 4, 2048))"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"q1B67JE2VOL9"},"source":["fidf_array = []\r\n","nofidf_array = []\r\n","for i in range(fidf.shape[0]):\r\n","  fidf_array.append(fidf[i].flatten())\r\n","  nofidf_array.append(nofidf[i].flatten())\r\n","\r\n","fidf_array = np.array(fidf_array)\r\n","nofidf_array = np.array(nofidf_array)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"v7ttF82NWIkt"},"source":["fi_train, fi_test, nofi_train, nofi_test = train_test_split(fidf_array,nofidf_array,test_size=0.13,random_state=random_state)\n","x_train = np.vstack([fi_train,nofi_train])\n","y_train = np.hstack((np.full(len(fi_train),1),np.full(len(nofi_train),0)))\n","x_test = np.vstack([fi_test,nofi_test])\n","y_test = np.hstack([np.full(len(fi_test),1),np.full(len(nofi_test),0)])"],"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((260, 8192), (40, 8192), (260,), (40,))"]},"metadata":{},"execution_count":6}],"source":["x_train.shape, x_test.shape, y_train.shape, y_test.shape"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(40, 8192)"]},"metadata":{},"execution_count":7}],"source":["x_test.shape"]},{"cell_type":"markdown","metadata":{"id":"p3lFBYvyoVRB"},"source":["# **Running Model**"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import cross_val_score, cross_val_predict\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","def print_score(clf, X_train, y_train, X_test, y_test):\n","    '''\n","    print the accuracy score, classification report and confusion matrix of classifier\n","    '''\n","    '''\n","    training performance\n","    '''    \n","    print(\"Train Result:\\n\")\n","    print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_train, clf.predict(X_train))))\n","    \n","    print(\"Classification Report: \\n {}\\n\".format(classification_report(y_train, clf.predict(X_train))))        \n","    print(\"Train Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_train, clf.predict(X_train))))        \n","\n","    res = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n","    print(\"Average Accuracy: \\t {0:.4f}\".format(np.mean(res)))\n","    print(\"Accuracy SD: \\t\\t {0:.4f}\".format(np.std(res)))\n","    \n","    '''\n","    test performance\n","    '''\n","    print(\"Test Result:\\n\")        \n","    print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, clf.predict(X_test))))\n","    print(\"Classification Report: \\n {}\\n\".format(classification_report(y_test, clf.predict(X_test))))\n","    print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, clf.predict(X_test))))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","def get_score(clf, X_test, y_test):\n","        y_pred = clf.predict(X_test)\n","        report = classification_report(y_test,y_pred,output_dict=True)\n","        label_0 = report['0']\n","        label_1 = report['1']\n","        precision = np.array([label_0['precision'],label_1['precision']])\n","        recall = np.array([label_0['recall'],label_1['recall']])\n","        f1_score = np.array([label_0['f1-score'],label_1['f1-score']])\n","        cfmat = confusion_matrix(y_test,y_pred)\n","        return precision, recall, f1_score, cfmat"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["pre_data_types = ['smote','bootstrap']"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from imblearn.over_sampling import SMOTE\n","from sklearn.utils import resample\n","def get_imbalance_data(fi_train_,nofi_train_,rate,balance_type=None):\n","    temp_train, _ = train_test_split(fi_train_,test_size=1-rate,random_state=random_state)\n","    if balance_type == 'bootstrap':\n","        temp_train = resample(temp_train,n_samples=len(nofi_train),random_state=random_state)\n","    x_train = np.vstack([temp_train,nofi_train_])\n","    y_train = np.hstack([np.full(len(temp_train),1),np.full(len(nofi_train_),0)])\n","    if balance_type == 'smote':\n","        smote = SMOTE(random_state=42)\n","        x_train, y_train = smote.fit_resample(x_train,y_train)\n","    # print(temp_train.shape,nofi_train.shape,x_train.shape,y_train.shape)\n","    return x_train, y_train"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def model_run_data_imbalance(model,from_rate, to_rate = 1,sep = 0.11,save_folder='./',balance_type=None):\n","    assert from_rate is not None, 'from_rate must have value'\n","    columns=['no-fight','fight','rate','model']\n","    df_p  = pd.DataFrame(columns=columns)\n","    df_r  = pd.DataFrame(columns=columns)\n","    df_f1  = pd.DataFrame(columns=columns)\n","    cf_list = []\n","    for rate in np.arange(from_rate,to_rate,sep):\n","        rate = np.round(rate,2)\n","        x_tr, y_tr = None, None\n","        if np.isclose(rate,1):\n","            x_tr, y_tr = x_train, y_train\n","        elif rate < 1:\n","            x_tr, y_tr = get_imbalance_data(fi_train,nofi_train,rate,balance_type)\n","        else:\n","            print('Rate không được lớn hơn 1')\n","            break        \n","        x_te, y_te = x_test, y_test\n","        for key in model.keys():\n","            path = save_folder\n","            filename = str(rate).replace('.','')+'_'+key+'.sav'\n","            if balance_type in pre_data_types:\n","                filename = balance_type+'_'+filename\n","            path = path+filename\n","            clf = None\n","            if os.path.isfile(path) is False:\n","                clf = model[key]\n","                clf.fit(x_tr, y_tr)\n","                pickle.dump(clf, open(path, 'wb'))\n","            else:\n","                clf = pickle.load(open(path, 'rb'))\n","            # print(key+' Result:\\n')\n","            # print_score(clf,x_tr,y_tr,x_te,y_te)\n","            p,r,f1, cfmat = get_score(clf,x_te,y_te)\n","            p = np.round(p,3)\n","            r = np.round(r,3)\n","            f1 = np.round(f1,3)\n","            cf_list.append(cfmat)\n","            df_p = df_p.append({columns[0]: p[0],columns[1]: p[1],columns[2]:rate,columns[3]:key},ignore_index=True)\n","            df_r = df_r.append({columns[0]: r[0],columns[1]: r[1],columns[2]:rate,columns[3]:key},ignore_index=True)\n","            df_f1 = df_f1.append({columns[0]: f1[0],columns[1]: f1[1],columns[2]:rate,columns[3]:key},ignore_index=True)\n","    return df_p, df_r, df_f1, cf_list"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from sklearn.naive_bayes import BernoulliNB\n","from sklearn.svm import SVC\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from imblearn.ensemble import BalancedBaggingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from xgboost import XGBClassifier\n","\n","# Add or delete model you want\n","model = {\n","    'bernoulliNB' : BernoulliNB(binarize=0.0),\n","    'svm_poly': SVC(kernel='poly',random_state=random_state),\n","    'decision_tree': DecisionTreeClassifier(criterion = \"gini\", max_depth = 10,random_state=random_state),\n","    'sgd_05': SGDClassifier(alpha = 0.5,random_state=random_state),\n","    'randomforest': RandomForestClassifier(n_estimators=200,max_depth=10,criterion='gini',random_state=random_state,n_jobs=-1),\n","    'balanced_bag': BalancedBaggingClassifier(random_state=random_state),\n","    'bag_id3': BaggingClassifier(DecisionTreeClassifier(random_state=random_state), max_samples=0.8, max_features=0.8,random_state=random_state),\n","    'adaboost': AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state), n_estimators=10, learning_rate=1, random_state=random_state),\n","    'xgboost': XGBClassifier(max_depth=20, n_estimators=1000, learning_rate=0.3, n_jobs=-1),\n","    'knn_n1': KNeighborsClassifier(n_neighbors=1),\n","    'knn_n17': KNeighborsClassifier(n_neighbors=17),\n","}"]},{"source":["***"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":14,"metadata":{"tags":[]},"outputs":[],"source":["df_precision, df_recall, df_f1s, cfmatrix_list = model_run_data_imbalance(model,0.1,1.01,0.1,'./model_with_smote/','smote')"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def save_scores(folder,dic_scores):\n","    for key in dic_scores.keys():\n","        dic_scores[key].to_csv(folder+key+'.csv')"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["dic_scores ={\n","    'precision_score':df_precision,\n","    'recall_score':df_recall,\n","    'f1-score':df_f1s\n","}"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["save_scores('./scores/smote_',dic_scores)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["model_names = np.array(list(model.items()))[:,0].flatten()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["np.save('model_names.npy',model_names)"]},{"source":["***"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["#test\n","obj = {\n","    'knn_n17': KNeighborsClassifier(n_neighbors=17),\n","}\n","df_precision, df_recall, df_f1s, cfmatrix_list = model_run_data_imbalance(obj,0.1,0.2,0.1,'./model_with_smote/','smote')"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[10, 10],\n","        [ 0, 20]], dtype=int64)]"]},"metadata":{},"execution_count":18}],"source":["cfmatrix_list"]},{"source":["***"],"cell_type":"markdown","metadata":{}},{"source":["Tìm K phù hợp cho KNN"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["xt_train, yt_train = get_imbalance_data(fi_train,nofi_train,0.1)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0:  0.875 0.7 0.7777777777777777\n","1:  0.75 0.9 0.8181818181818182\n","0:  0.68 0.85 0.7555555555555556\n","1:  0.8 0.6 0.6857142857142857\n","0:  0.8666666666666667 0.65 0.7428571428571429\n","1:  0.72 0.9 0.7999999999999999\n","0:  0.6956521739130435 0.8 0.7441860465116279\n","1:  0.7647058823529411 0.65 0.7027027027027027\n","0:  0.8125 0.65 0.7222222222222223\n","1:  0.7083333333333334 0.85 0.7727272727272727\n","0:  0.72 0.9 0.7999999999999999\n","1:  0.8666666666666667 0.65 0.7428571428571429\n","0:  0.8947368421052632 0.85 0.8717948717948718\n","1:  0.8571428571428571 0.9 0.8780487804878048\n","0:  0.782608695652174 0.9 0.8372093023255814\n","1:  0.8823529411764706 0.75 0.8108108108108107\n","0:  0.8888888888888888 0.8 0.8421052631578948\n","1:  0.8181818181818182 0.9 0.8571428571428572\n","0:  0.8571428571428571 0.9 0.8780487804878048\n","1:  0.8947368421052632 0.85 0.8717948717948718\n","0:  0.9444444444444444 0.85 0.8947368421052632\n","1:  0.8636363636363636 0.95 0.9047619047619048\n","0:  0.85 0.85 0.85\n","1:  0.85 0.85 0.85\n","0:  0.8947368421052632 0.85 0.8717948717948718\n","1:  0.8571428571428571 0.9 0.8780487804878048\n","0:  0.8181818181818182 0.9 0.8571428571428572\n","1:  0.8888888888888888 0.8 0.8421052631578948\n","0:  0.8095238095238095 0.85 0.8292682926829269\n","1:  0.8421052631578947 0.8 0.8205128205128205\n","0:  0.782608695652174 0.9 0.8372093023255814\n","1:  0.8823529411764706 0.75 0.8108108108108107\n","0:  0.8095238095238095 0.85 0.8292682926829269\n","1:  0.8421052631578947 0.8 0.8205128205128205\n","0:  0.7916666666666666 0.95 0.8636363636363635\n","1:  0.9375 0.75 0.8333333333333334\n","0:  0.85 0.85 0.85\n","1:  0.85 0.85 0.85\n"]}],"source":["pre = []\n","rcl = []\n","f1s = []\n","for k in range(1,20):\n","    knn = KNeighborsClassifier(n_neighbors=k)\n","    knn.fit(x_train,y_train)\n","    cr = classification_report(y_test,knn.predict(x_test),output_dict=True)\n","    pre.append([cr['0']['precision'],cr['1']['precision']])\n","    rcl.append([cr['0']['recall'],cr['1']['recall']])\n","    f1s.append([cr['0']['f1-score'],cr['1']['f1-score']])\n","    print('0: ',pre[k-1][0], rcl[k-1][0],f1s[k-1][0])\n","    print('1: ',pre[k-1][1], rcl[k-1][1],f1s[k-1][1])"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["pre = np.array(pre)\n","rcl = np.array(rcl)\n","f1s = np.array(f1s)"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 17)"]},"metadata":{},"execution_count":46}],"source":["np.argmax(pre[:,0]),np.argmax(pre[:,1])"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(17, 10)"]},"metadata":{},"execution_count":47}],"source":["np.argmax(rcl[:,0]),np.argmax(rcl[:,1])"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 10)"]},"metadata":{},"execution_count":48}],"source":["np.argmax(f1s[:,0]),np.argmax(f1s[:,1])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}